# Real-Time Summarization using Transformers

## ğŸ“Œ Overview

This repository contains implementations for real-time text summarization using transformer-based models such as BERT, T5, and GPT. It includes foundational concepts like attention mechanisms and transformer architectures, along with applied implementations for dialogue summarization and API-based text summarization.

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ BERTandT5.ipynb                     # Introduction to Transformers (PPT + implementation)
â”œâ”€â”€ Dialougue_Summarization_GPT_model.ipynb # GPT-based dialogue summarization with API integration
â”œâ”€â”€ Home.ipynb                           # BERT from scratch + T5 pretrained summarization
â”œâ”€â”€ Source.ipynb                         # Attention mechanism and transformer fundamentals
â”œâ”€â”€ README.md                            # Project documentation
```

## ğŸ“œ Detailed File Description

### 1ï¸âƒ£ BERTandT5.ipynb â€“ Introduction to Transformers & Summarization

- Contains a PPT (presentation) introducing Transformer architectures.
- Covers Self-Attention, Multi-Head Attention, and Feed-Forward Networks.
- Explains BERT and T5 models and their applications in text summarization.
- Includes a practical summarization script using T5 pretrained weights.

#### ğŸ”¹ Key Features
- âœ” Understanding Transformer models
- âœ” Using T5 for text summarization
- âœ” Comparison of BERT and T5 architectures

---

### 2ï¸âƒ£ Dialougue_Summarization_GPT_model.ipynb â€“ GPT-Based Dialogue Summarization

- Implements dialogue summarization using GPT-based models.
- Calls OpenAIâ€™s GPT API to generate and summarize dialogues dynamically.
- Works on structured and unstructured conversation formats.

#### ğŸ”¹ Key Features
- âœ” Uses GPT API for text generation and summarization
- âœ” Handles conversational data efficiently
- âœ” Supports integration into chatbots and customer service applications

#### Usage Example:
```python
import openai

response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=[{"role": "user", "content": "Summarize the following conversation..."}]
)
print(response["choices"][0]["message"]["content"])
```

---

### 3ï¸âƒ£ Home.ipynb â€“ BERT Implementation from Scratch + T5 Summarization

- Implements BERT from scratch, demonstrating tokenization, embedding, and attention.
- Uses pretrained T5 model for document-level text summarization.
- Compares extractive vs. abstractive summarization.

#### ğŸ”¹ Key Features
- âœ” Custom BERT implementation (tokenizer, embeddings, self-attention)
- âœ” Summarization with T5 (pretrained weights)
- âœ” Performance evaluation using ROUGE scores

---

### 4ï¸âƒ£ Source.ipynb â€“ Attention Mechanism & Transformer Fundamentals

- Breaks down the attention mechanism into step-by-step implementations.
- Covers Scaled Dot-Product Attention, Positional Encoding, and Transformer Architecture.
- Implements key transformer components using PyTorch.

#### ğŸ”¹ Key Features
- âœ” Hands-on implementation of Self-Attention
- âœ” Mathematical breakdown of Positional Encoding
- âœ” Step-by-step Transformer Model Building

#### Example: Self-Attention Mechanism
```python
import torch
import torch.nn.functional as F

def self_attention(Q, K, V):
    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(K.size(-1)))
    attention_weights = F.softmax(scores, dim=-1)
    return torch.matmul(attention_weights, V)

# Example usage
Q = K = V = torch.rand(3, 4)
output = self_attention(Q, K, V)
print(output)
```

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Install Dependencies
```sh
pip install transformers openai torch fastapi uvicorn
```

### 2ï¸âƒ£ Running the Transformer Models in Jupyter
Open any notebook (`.ipynb`) in JupyterLab or Google Colab and execute the cells.

### 3ï¸âƒ£ Running the GPT API for Summarization
- Get an OpenAI API Key and update it in `Dialougue_Summarization_GPT_model.ipynb`.
- Run the notebook to process conversations.

### 4ï¸âƒ£ Running a Simple FastAPI Server for Summarization
```sh
uvicorn app:main --reload
```
Then send a request:
```sh
curl -X POST "http://127.0.0.1:8000/summarize/" -H "Content-Type: application/json" -d '{"text": "Your long text here"}'
```

---

## ğŸ“Š Performance Metrics

- Uses ROUGE Score to evaluate summarization quality.
- Benchmarks GPT vs. T5 for summarization accuracy.
- Compares extractive vs. abstractive summarization.

---

## ğŸ“Œ Future Improvements

âœ… Implement real-time Kafka streaming for large-scale summarization.
âœ… Optimize transformer models with ONNX for better inference speed.
âœ… Integrate dialogue summarization into chatbots for customer service.
