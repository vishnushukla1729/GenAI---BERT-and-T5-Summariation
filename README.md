âœ¨ Summarization using Bert and SimpleT5 with Greedy Decoding âœ¨
Added a Pipeline Summarizer for easy understanding how it works
ğŸ–‹ Author

Vishnu Sujeetkumar ShuklağŸ“ Graduate Student Researcher, Computational Imaging and Sensing LabğŸ« University of California, Riverside

ğŸ“Œ Overview

This project demonstrates a simple text summarization pipeline using a transformer-based approach. The model follows a T5-like structure and employs greedy decoding to generate concise summaries from input paragraphs.

ğŸš€ Features

âœ… Implements a basic encoder-decoder transformer model (SimpleT5).âœ… Uses a toy tokenizer for word-level tokenization.âœ… Employs greedy decoding for text generation.âœ… Compatible with both CPU and GPU environments.

ğŸ”§ Installation

Ensure you have Python 3.7+ installed along with PyTorch. Install the necessary dependencies using:

pip install torch

â–¶ï¸ Usage

Run the script to process an input paragraph and generate a summary:

python summarizer.py

ğŸ“œ Example Output

ğŸ“ Input Paragraph:

"Artificial Intelligence has revolutionized many industries. Deep learning techniques are now widely adopted in tasks such as speech recognition, computer vision, and natural language processing. The rapid development of AI technologies has led to significant breakthroughs and continues to drive innovative solutions."

âœ¨ Generated Summary:

"AI drives innovation with deep learning in speech and vision."

ğŸ“ File Structure

.
â”œâ”€â”€ summarizer.py       # Main script implementing summarization
â”œâ”€â”€ README.md           # Documentation

ğŸ”® Future Work

ğŸ”¹ Train the model on real-world datasets.ğŸ”¹ Enhance decoding strategies using beam search.ğŸ”¹ Implement a more sophisticated tokenizer.

ğŸ“œ License

ğŸ“ MIT License


